{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# determine whether a person makes over 50K a year."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a regression problem as target variable Salary is '>50K' or '=<50K'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39                  0\n",
      "State-gov        1836\n",
      "77516               0\n",
      "Bachelors           0\n",
      "13                  0\n",
      "Never-married       0\n",
      "Adm-clerical     1843\n",
      "Not-in-family       0\n",
      "White               0\n",
      "Male                0\n",
      "2174                0\n",
      "0                   0\n",
      "40                  0\n",
      "United-States     583\n",
      "<=50K               0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Reading the daaset, considering the '?' as NA value \n",
    "df = pd.read_csv(\"adult.data\",na_values=\"?\", skipinitialspace=True)\n",
    "# Checking the null counts\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['39', 'State-gov', '77516', 'Bachelors', '13', 'Never-married',\n",
      "       'Adm-clerical', 'Not-in-family', 'White', 'Male', '2174', '0', '40',\n",
      "       'United-States', '<=50K'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Printing all the columns\n",
    "print(df.columns)\n",
    "# From this it looks like column names are not correct, renaming them\n",
    "df.columns = ['Age', 'Workclass', 'fnlwgt', 'Education', 'Education-num', 'Marital-status', \\\n",
    "              'Occupation', 'Relationship', 'Race', 'Sex', 'Capital-gain', 'Capital-loss', \\\n",
    "              'Hours-per-week', 'Native-country', 'Earning']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Age', 'Workclass', 'fnlwgt', 'Education', 'Education-num',\n",
      "       'Marital-status', 'Occupation', 'Relationship', 'Race', 'Sex',\n",
      "       'Capital-gain', 'Capital-loss', 'Hours-per-week', 'Native-country',\n",
      "       'Earning'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Age                  0\n",
       "Workclass         1836\n",
       "fnlwgt               0\n",
       "Education            0\n",
       "Education-num        0\n",
       "Marital-status       0\n",
       "Occupation        1843\n",
       "Relationship         0\n",
       "Race                 0\n",
       "Sex                  0\n",
       "Capital-gain         0\n",
       "Capital-loss         0\n",
       "Hours-per-week       0\n",
       "Native-country     583\n",
       "Earning              0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rows_before_droppinig = df.shape[0]\n",
    "# Printing all the columns\n",
    "print(df.columns)\n",
    "\n",
    "# Checking the NA values\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping the NA values which is actually 7.368% of total Data\n",
    "# It is observed that in most of the missing data set, \n",
    "# the ‘workclass’ variable and ‘occupation’ variable are missing data together. \n",
    "# And the remaining have ‘nativecountry’ variable missing. We could handle the \n",
    "# missing values by imputing the data. However, since ‘workclass’, ‘occupation’ \n",
    "# and ‘nativecountry’ could potentially be very good predictors of income, \n",
    "# imputing may simply skew the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Age               0\n",
      "Workclass         0\n",
      "fnlwgt            0\n",
      "Education         0\n",
      "Education-num     0\n",
      "Marital-status    0\n",
      "Occupation        0\n",
      "Relationship      0\n",
      "Race              0\n",
      "Sex               0\n",
      "Capital-gain      0\n",
      "Capital-loss      0\n",
      "Hours-per-week    0\n",
      "Native-country    0\n",
      "Earning           0\n",
      "dtype: int64\n",
      "Total number of rows dropped is 2399 wich is 7.368% of total rows.\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "df_opt = df.dropna()\n",
    "rows_after_droppinig = df_opt.shape[0]\n",
    "\n",
    "# Checking the NA values\n",
    "print(df_opt.isnull().sum())\n",
    "\n",
    "# number of rows dropped\n",
    "diff = rows_before_droppinig - rows_after_droppinig\n",
    "print(\"Total number of rows dropped is {} wich is {:.4}% of total rows.\"   \\\n",
    "              .format(diff,(diff/rows_before_droppinig)*100))\n",
    "print('-'*50)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "['Age', 'Workclass', 'fnlwgt', 'Education', 'Education-num',\n",
    "       'Marital-status', 'Occupation', 'Relationship', 'Race', 'Sex',\n",
    "       'Capital-gain', 'Capital-loss', 'Hours-per-week', 'Native-country',\n",
    "       'Earning'],\n",
    "      dtype='object'\n",
    "      \n",
    "Out of these 'Workclass', 'Education', 'Marital-status', 'Occupation', 'Relationship', 'Race', 'Sex', 'Native-country' \n",
    "And  'Earning' are the catagorical values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# applying one hot and lebel encoding on these columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total numbers of unique values in catagorical features are: \n",
      "Workclasshas total : 9\n",
      "Educationhas total : 16\n",
      "Marital-statushas total : 7\n",
      "Occupationhas total : 15\n",
      "Relationshiphas total : 6\n",
      "Racehas total : 5\n",
      "Sexhas total : 2\n",
      "Native-countryhas total : 42\n",
      "Earninghas total : 2\n"
     ]
    }
   ],
   "source": [
    "# Fist print the unique values of each features.\n",
    "cat_features = ['Workclass', 'Education', 'Marital-status', 'Occupation', 'Relationship',\\\n",
    "                'Race', 'Sex', 'Native-country', 'Earning' ]\n",
    "print(\"Total numbers of unique values in catagorical features are: \")\n",
    "\n",
    "for feature in cat_features:\n",
    "    print(feature + \"has total : \" + str(len(df[feature].unique())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/arv/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "# Applying One hot encoding on only catagorical columns, i.e. preferred_foot\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "for feature in cat_features:\n",
    "    #feature = 'Workclass'\n",
    "    df_opt[feature] = label_encoder.fit_transform(df_opt[feature])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>Education</th>\n",
       "      <th>Education-num</th>\n",
       "      <th>Marital-status</th>\n",
       "      <th>Occupation</th>\n",
       "      <th>Relationship</th>\n",
       "      <th>Race</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Capital-gain</th>\n",
       "      <th>Capital-loss</th>\n",
       "      <th>Hours-per-week</th>\n",
       "      <th>Native-country</th>\n",
       "      <th>Earning</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50</td>\n",
       "      <td>4</td>\n",
       "      <td>83311</td>\n",
       "      <td>9</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38</td>\n",
       "      <td>2</td>\n",
       "      <td>215646</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>53</td>\n",
       "      <td>2</td>\n",
       "      <td>234721</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>28</td>\n",
       "      <td>2</td>\n",
       "      <td>338409</td>\n",
       "      <td>9</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>37</td>\n",
       "      <td>2</td>\n",
       "      <td>284582</td>\n",
       "      <td>12</td>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age  Workclass  fnlwgt  Education  Education-num  Marital-status  \\\n",
       "0   50          4   83311          9             13               2   \n",
       "1   38          2  215646         11              9               0   \n",
       "2   53          2  234721          1              7               2   \n",
       "3   28          2  338409          9             13               2   \n",
       "4   37          2  284582         12             14               2   \n",
       "\n",
       "   Occupation  Relationship  Race  Sex  Capital-gain  Capital-loss  \\\n",
       "0           3             0     4    1             0             0   \n",
       "1           5             1     4    1             0             0   \n",
       "2           5             0     2    1             0             0   \n",
       "3           9             5     2    0             0             0   \n",
       "4           3             5     4    0             0             0   \n",
       "\n",
       "   Hours-per-week  Native-country  Earning  \n",
       "0              13              38        0  \n",
       "1              40              38        0  \n",
       "2              40              38        0  \n",
       "3              40               4        0  \n",
       "4              40              38        0  "
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data after one hot encodng of all catagorical data\n",
    "df_opt.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splitting the train and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining X and y from the Dataset\n",
    "X = df_opt.iloc[:,:-1]\n",
    "y = df_opt.Earning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.10,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###########################Backward Elemination###########################\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                Earning   R-squared:                       0.262\n",
      "Model:                            OLS   Adj. R-squared:                  0.262\n",
      "Method:                 Least Squares   F-statistic:                     766.4\n",
      "Date:                Fri, 14 Sep 2018   Prob (F-statistic):               0.00\n",
      "Time:                        21:05:17   Log-Likelihood:                -12917.\n",
      "No. Observations:               30161   AIC:                         2.586e+04\n",
      "Df Residuals:                   30146   BIC:                         2.599e+04\n",
      "Df Model:                          14                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const         -0.5827      0.023    -25.272      0.000      -0.628      -0.537\n",
      "x1             0.0052      0.000     29.600      0.000       0.005       0.006\n",
      "x2            -0.0148      0.002     -6.552      0.000      -0.019      -0.010\n",
      "x3          7.118e-08   2.04e-08      3.492      0.000    3.12e-08    1.11e-07\n",
      "x4            -0.0035      0.001     -5.777      0.000      -0.005      -0.002\n",
      "x5             0.0485      0.001     52.606      0.000       0.047       0.050\n",
      "x6            -0.0230      0.002    -15.163      0.000      -0.026      -0.020\n",
      "x7             0.0012      0.001      2.188      0.029       0.000       0.002\n",
      "x8            -0.0160      0.002     -9.253      0.000      -0.019      -0.013\n",
      "x9             0.0152      0.003      5.817      0.000       0.010       0.020\n",
      "x10            0.1117      0.006     19.528      0.000       0.100       0.123\n",
      "x11         9.192e-06   2.93e-07     31.378      0.000    8.62e-06    9.77e-06\n",
      "x12            0.0001   5.33e-06     21.201      0.000       0.000       0.000\n",
      "x13            0.0035      0.000     18.177      0.000       0.003       0.004\n",
      "x14           -0.0006      0.000     -1.656      0.098      -0.001       0.000\n",
      "==============================================================================\n",
      "Omnibus:                     2688.408   Durbin-Watson:                   2.003\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             3229.187\n",
      "Skew:                           0.779   Prob(JB):                         0.00\n",
      "Kurtosis:                       2.624   Cond. No.                     2.35e+06\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 2.35e+06. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n",
      "###########################################################################\n",
      "Here from OLS summary we can see none of the feature is having P value > 0.05 \n",
      "Hence all features seems to be significant, nothing can be dropped. \n",
      "###########################################################################\n"
     ]
    }
   ],
   "source": [
    "backwardEle(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/arv/anaconda3/lib/python3.6/site-packages/pandas/core/frame.py:3697: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  errors=errors)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>Education</th>\n",
       "      <th>Education-num</th>\n",
       "      <th>Marital-status</th>\n",
       "      <th>Occupation</th>\n",
       "      <th>Relationship</th>\n",
       "      <th>Race</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Capital-gain</th>\n",
       "      <th>Capital-loss</th>\n",
       "      <th>Hours-per-week</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20590</th>\n",
       "      <td>35</td>\n",
       "      <td>2</td>\n",
       "      <td>361888</td>\n",
       "      <td>15</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30652</th>\n",
       "      <td>45</td>\n",
       "      <td>2</td>\n",
       "      <td>83064</td>\n",
       "      <td>9</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1200</th>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>235271</td>\n",
       "      <td>9</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25333</th>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "      <td>236069</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6242</th>\n",
       "      <td>47</td>\n",
       "      <td>2</td>\n",
       "      <td>436770</td>\n",
       "      <td>8</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Age  Workclass  fnlwgt  Education  Education-num  Marital-status  \\\n",
       "20590   35          2  361888         15             10               0   \n",
       "30652   45          2   83064          9             13               2   \n",
       "1200    30          1  235271          9             13               2   \n",
       "25333   18          2  236069          0              6               4   \n",
       "6242    47          2  436770          8             11               4   \n",
       "\n",
       "       Occupation  Relationship  Race  Sex  Capital-gain  Capital-loss  \\\n",
       "20590           6             4     4    1             0             0   \n",
       "30652          11             0     4    1             0             0   \n",
       "1200            9             0     4    1             0             0   \n",
       "25333           7             3     2    1             0             0   \n",
       "6242            9             1     4    0             0             0   \n",
       "\n",
       "       Hours-per-week  \n",
       "20590              40  \n",
       "30652              50  \n",
       "1200               50  \n",
       "25333              10  \n",
       "6242               40  "
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Here We can see X14 i.e. \"Native-country\" is having P value > 0.05\n",
    "# o better to eleminate this column\n",
    "X_train.drop(['Native-country'], axis=1, inplace=True)\n",
    "\n",
    "# Same time drop this column from test set as well\n",
    "X_test.drop(['Native-country'], axis=1, inplace=True)\n",
    "\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###########################Backward Elemination###########################\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                Earning   R-squared:                       0.262\n",
      "Model:                            OLS   Adj. R-squared:                  0.262\n",
      "Method:                 Least Squares   F-statistic:                     766.4\n",
      "Date:                Fri, 14 Sep 2018   Prob (F-statistic):               0.00\n",
      "Time:                        21:05:18   Log-Likelihood:                -12917.\n",
      "No. Observations:               30161   AIC:                         2.586e+04\n",
      "Df Residuals:                   30146   BIC:                         2.599e+04\n",
      "Df Model:                          14                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const         -0.5827      0.023    -25.272      0.000      -0.628      -0.537\n",
      "x1             0.0052      0.000     29.600      0.000       0.005       0.006\n",
      "x2            -0.0148      0.002     -6.552      0.000      -0.019      -0.010\n",
      "x3          7.118e-08   2.04e-08      3.492      0.000    3.12e-08    1.11e-07\n",
      "x4            -0.0035      0.001     -5.777      0.000      -0.005      -0.002\n",
      "x5             0.0485      0.001     52.606      0.000       0.047       0.050\n",
      "x6            -0.0230      0.002    -15.163      0.000      -0.026      -0.020\n",
      "x7             0.0012      0.001      2.188      0.029       0.000       0.002\n",
      "x8            -0.0160      0.002     -9.253      0.000      -0.019      -0.013\n",
      "x9             0.0152      0.003      5.817      0.000       0.010       0.020\n",
      "x10            0.1117      0.006     19.528      0.000       0.100       0.123\n",
      "x11         9.192e-06   2.93e-07     31.378      0.000    8.62e-06    9.77e-06\n",
      "x12            0.0001   5.33e-06     21.201      0.000       0.000       0.000\n",
      "x13            0.0035      0.000     18.177      0.000       0.003       0.004\n",
      "x14           -0.0006      0.000     -1.656      0.098      -0.001       0.000\n",
      "==============================================================================\n",
      "Omnibus:                     2688.408   Durbin-Watson:                   2.003\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             3229.187\n",
      "Skew:                           0.779   Prob(JB):                         0.00\n",
      "Kurtosis:                       2.624   Cond. No.                     2.35e+06\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 2.35e+06. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n",
      "###########################################################################\n",
      "Here from OLS summary we can see none of the feature is having P value > 0.05 \n",
      "Hence all features seems to be significant, nothing can be dropped. \n",
      "###########################################################################\n"
     ]
    }
   ],
   "source": [
    "backwardEle(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# After eleminating 'Native-country', there is no more columns which are having P value > 0.05\n",
    "# i.e. No more eleminations are required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Applying models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7912982611258473"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Applying Logistic regression\n",
    "# Logistic Regression \n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "classifier=LogisticRegression()\n",
    "classifier.fit(X_train,y_train)\n",
    "scor=classifier.score(X_train,y_train)\n",
    "scor"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# improvement required"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7880036220844221\n"
     ]
    }
   ],
   "source": [
    "# Cross validation from SKlearn\n",
    "\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "cv = cross_val_score(estimator = classifier, X=X,y=y,scoring='accuracy',cv=50)\n",
    "print(cv.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8409015578389128\n"
     ]
    }
   ],
   "source": [
    "# DecisionTreeClassifier\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dtree = DecisionTreeClassifier(criterion='entropy', max_depth=5, random_state=0)\n",
    "dtree.fit(X_train, y_train)\n",
    "tscore=dtree.score(X_test, y_test)\n",
    "print(tscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8528339410009944\n"
     ]
    }
   ],
   "source": [
    "# RandomForestRegressor\n",
    "\n",
    "# Try different numbers of n_estimators - this will take a while or so\n",
    "\n",
    "regr_rf = RandomForestClassifier(max_depth=30, random_state=2)\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "estimators = np.arange(100, 200, 10)\n",
    "scores = []\n",
    "for n in estimators:\n",
    "    regr_rf.set_params(n_estimators=n)\n",
    "    regr_rf.fit(X_train, y_train)\n",
    "    scores.append(regr_rf.score(X_test, y_test))\n",
    "    #print(scores)\n",
    "#max_sc_idx = scores.index(max(scores))\n",
    "\n",
    "print(max(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.848193569771296\n"
     ]
    }
   ],
   "source": [
    "# Bagging\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "bg=BaggingClassifier(DecisionTreeClassifier(),n_estimators=20, max_samples = 0.5, max_features=1.0)\n",
    "bg.fit(X_train,y_train)\n",
    "bgscore=bg.score(X_test,y_test)\n",
    "print(bgscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.848193569771296\n"
     ]
    }
   ],
   "source": [
    "# Boosting\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "bo=AdaBoostClassifier(n_estimators=50, learning_rate=1.)\n",
    "bo.fit(X_train,y_train)\n",
    "boscore=bo.score(X_test,y_test)\n",
    "print(bgscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8623636899498969\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/arv/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "#fitting XGBoost to the Training set\n",
    "import xgboost\n",
    "classifier = xgboost.XGBClassifier()\n",
    "classifier.fit(X_train,y_train)\n",
    "cscore=classifier.score(X_train,y_train)\n",
    "print(cscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
